{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Análise de Desigualdade em Saúde no modelo HEAT/OMS\n",
    "## Bloco 2025/1 = análise do sistema de mortalidade do SUS com agregação por unidades federativas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aspectos gerais e participantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto Desenvolvido em parceria da MS/SECTICS/DESID com a Organização Mundial de Saúde\n",
    "\n",
    "Elaborado em linguagem Python, utilizando a biblioteca pysus para acesso ao SIM (Sistema de Informações de Mortalidade do SUS)\n",
    "\n",
    "Coordenador-geral:\n",
    "\n",
    "Coordenadores: \n",
    "\n",
    "Cientista de dados: Marcos Mesquita\n",
    "\n",
    "Outros participantes:\n",
    "\n",
    "Data: 06/12/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O principal objetivo desse projeto é realizar a avaliação de desigualdade na saúde no Brasil com ênfase para a dimensão de unidades subnacionais, estados e municípios brasileiros, a partir da aplicação do modelo do HEAT, tendo como objetivos específicos:\n",
    "\n",
    "- Apresentar indicadores de saúde no Brasil desagregados por subunidades nacionais em uma visualização interativa a partir do modelo do HEAT Plus;\n",
    "- Oferecer um repositório comum e atualizado com dados de desigualdade da saúde no Brasil desagregados por estados e municípios em um modelo sob reconhecimento internacional;\n",
    "- Permitir exploração e acesso dos dados e da metodologia para outros tipos de análises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1 - Definição do Bloco\n",
    "\n",
    "O projeto ocorrerá em blocos sucessivos, nos quais serão definidos o problema e os indicadores a serem analisados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do problema do bloco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " H0 - as unidades federativa são variáveis determinantes para mortalidade no país"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escopo do Bloco 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* indicador: mortalidade (número de mortes por população, dados de morte do SIM/SUS e dados populacionais pelo Censos de 2010 e 2022)\n",
    "* localização: todo o Brasil, com agregação de mortalidade por Estados e Municípios\n",
    "* período: 2010 e 2022 \n",
    "* doenças: “doenças evitáveis” conforme definido pelo OCDE\n",
    "* outros critérios de filtro: até 74 anos de idade (em razão da aplicação do critério de \"doenças evitáveis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 - Carga primária dos dados por bloco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspectos teóricos e técnicos das fontes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Aspectos técnicos - ambiente, linguagem e ferramentas principais\n",
    "\n",
    "A análise será feita utilizando a linguagem Python e a biblioteca Pysus que permite acesso às principais bases do SUS de forma direta.\n",
    "O Pysus exige um ambiente linux para execução de alguns comandos o que foi possível, mesmo em uma máquina Windows, a partir do WSL do Windows.\n",
    "Foi criado um ambiente em WSL e o conjunto da extração, tratamento e análise dos dados foi realizado no formato Notebook em um editor VSCode, dentro de um Dev Container: Default Linux Universal.\n",
    "\n",
    "\n",
    "#### Morte e mortalidade no HEAT\n",
    "\n",
    "Para entendermos como o HEAT trata a mortalidade, fizemos uma busca de indicadores de mortalidade no WHO Health Inequality Data Repository.\n",
    "\n",
    "O repositório traz dados e metadados de todos os indicadores utilizados pelo HEAT.\n",
    "Apresenta um total de 3915 indicadores, distribuídos entre 14 seções.\n",
    "\n",
    "Foi feita uma revisão geral dos indicadores relacionados à mortalidade, que depois foi refinada pela busca das seguintes palavras : “death”, “mortality”, “fatal”, ‘fatality” ,“Probability of dying”, “suicide”. E foram encontrados 388 indicadores que trazem uma destas expressões na sua descrição.\n",
    "\n",
    "\n",
    "#### SIM (Sistema de Informações de Mortalidade do SUS)\n",
    "\n",
    "A mortalidade e os indicadores de morte serão buscados no SIM (Sistema de Informações de Mortalidade do SUS).\n",
    "O SIM disponibiliza dados de mortes no Brasil desde 1996 por ocorrências, gerido pelo Departamento de Análise de Situação de Saúde, da Secretaria de Vigilância em Saúde do Ministério da Saúde, em conjunto com as Secretarias Estaduais e Municipais de Saúde. Estas últimas responsáveis efetivamente pela coleta dos dados.\n",
    "\n",
    "O SIM traz informações do indivíduo, como sexo, idade, localidade e causas da morte, classificadas de acordo com o CID (Classificação Internacional de Doenças e Problemas Relacionadas à Saúde).\n",
    "\n",
    "\n",
    "#### CID (Classificação Internacional de Doenças e Problemas Relacionadas à Saúde)\n",
    "\n",
    "Com o intuito de padronizar a nomenclatura de patologias e com abrangência para todo o mundo, foi elaborado pela Organização Mundial da Saúde (OMS) uma  classificação internacional de doenças, a CID (Classificação Internacional de Doenças e Problemas Relacionadas à Saúde). \n",
    "\n",
    "A Classificação é atualizada periodicamente. A versão mais atual é a CID11, publicada em janeiro de 2022.\n",
    "\n",
    "No entanto, por se tratar de revisão que traz impactos nos registros e que exige considerável atualização das ferramentas de captura das informações, o SIM utiliza versões anteriores da CID.\n",
    "- CID9 - dados até 1995\n",
    "- CID10 - a partir de 1996 até a data atual\n",
    "\n",
    "Em razão do recorte temporal dos dados, de 1998 a 2022, iremos utilizar somente a CID10.\n",
    "A CID10 é organizada em 22 capítulos e possui, além da classificação de doenças, descrição de códigos que permitem identificar sinais, sintomas, queixas, causas externas e circunstâncias sociais.\n",
    "\n",
    "\n",
    "#### CID de doenças evitáveis\n",
    "\n",
    "Como elemento do escopo deste trabalho iremos tratar de doenças evitáveis.\n",
    "\n",
    "O Brasil, a partir da Secretaria de Vigilância em Saúde apresenta uma classificação de doenças evitáveis. \n",
    "\n",
    "Lista de causas evitáveis pode ser encontrada nos links: http://tabnet.datasus.gov.br/cgi/sim/Obitos_Evitaveis_0_a_4_anos.pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### População (Censo)\n",
    "\n",
    "\n",
    "Os dados de população são os do Censo, acessados pelo site do IBGE, https://sidra.ibge.gov.br/Tabela/9606\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação e importação de bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: pip in /usr/local/python/3.13.1/lib/python3.13/site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0.1\n",
      "Collecting pysus\n",
      "  Downloading pysus-0.11.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting Unidecode<2.0.0,>=1.3.6 (from pysus)\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aioftp<0.22.0,>=0.21.4 (from pysus)\n",
      "  Downloading aioftp-0.21.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting bigtree<0.13.0,>=0.12.2 (from pysus)\n",
      "  Downloading bigtree-0.12.5-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting cffi==1.15.1 (from pysus)\n",
      "  Downloading cffi-1.15.1.tar.gz (508 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dateparser<2.0.0,>=1.1.8 (from pysus)\n",
      "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting dbfread==2.0.7 (from pysus)\n",
      "  Downloading dbfread-2.0.7-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting elasticsearch==7.16.2 (from elasticsearch[preprocessing]==7.16.2->pysus)\n",
      "  Downloading elasticsearch-7.16.2-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting fastparquet<0.9.0,>=0.8.1 (from pysus)\n",
      "  Downloading fastparquet-0.8.3.tar.gz (393 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting humanize<5.0.0,>=4.8.0 (from pysus)\n",
      "  Downloading humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting loguru<0.7.0,>=0.6.0 (from pysus)\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting numpy==1.26.2 (from pysus)\n",
      "  Downloading numpy-1.26.2.tar.gz (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.5.3 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from pysus) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=11.0.0 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from pysus) (19.0.0)\n",
      "Collecting pycparser==2.21 (from pysus)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyreaddbc>=1.1.0 (from pysus)\n",
      "  Downloading pyreaddbc-1.2.0.tar.gz (57 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-dateutil==2.8.2 (from pysus)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting tqdm==4.64.0 (from pysus)\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urwid<3.0.0,>=2.1.2 (from pysus)\n",
      "  Downloading urwid-2.6.16-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting wget<4.0,>=3.2 (from pysus)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting urllib3<2,>=1.21.1 (from elasticsearch==7.16.2->elasticsearch[preprocessing]==7.16.2->pysus)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.13/site-packages (from elasticsearch==7.16.2->elasticsearch[preprocessing]==7.16.2->pysus) (2024.12.14)\n",
      "\u001b[33mWARNING: elasticsearch 7.16.2 does not provide the extra 'preprocessing'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.13/site-packages (from python-dateutil==2.8.2->pysus) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2024.2 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from dateparser<2.0.0,>=1.1.8->pysus) (2024.2)\n",
      "Collecting regex!=2019.02.19,!=2021.8.27,>=2015.06.24 (from dateparser<2.0.0,>=1.1.8->pysus)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tzlocal>=0.2 (from dateparser<2.0.0,>=1.1.8->pysus)\n",
      "  Downloading tzlocal-5.3-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from fastparquet<0.9.0,>=0.8.1->pysus) (2.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/python/3.13.1/lib/python3.13/site-packages (from fastparquet<0.9.0,>=0.8.1->pysus) (2024.12.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.13/site-packages (from fastparquet<0.9.0,>=0.8.1->pysus) (24.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from pandas>=1.5.3->pysus) (2024.2)\n",
      "Requirement already satisfied: pyyaml>=6 in /home/codespace/.local/lib/python3.13/site-packages (from pyreaddbc>=1.1.0->pysus) (6.0.2)\n",
      "Collecting typing-extensions (from urwid<3.0.0,>=2.1.2->pysus)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.13/site-packages (from urwid<3.0.0,>=2.1.2->pysus) (0.2.13)\n",
      "Downloading pysus-0.11.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dbfread-2.0.7-py2.py3-none-any.whl (20 kB)\n",
      "Downloading elasticsearch-7.16.2-py2.py3-none-any.whl (385 kB)\n",
      "Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Downloading aioftp-0.21.4-py3-none-any.whl (37 kB)\n",
      "Downloading bigtree-0.12.5-py3-none-any.whl (63 kB)\n",
      "Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
      "Downloading humanize-4.11.0-py3-none-any.whl (128 kB)\n",
      "Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Downloading urwid-2.6.16-py3-none-any.whl (297 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.3-py3-none-any.whl (17 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: cffi, numpy, fastparquet, pyreaddbc, wget\n",
      "  Building wheel for cffi (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cffi: filename=cffi-1.15.1-cp313-cp313-linux_x86_64.whl size=473667 sha256=1a17984ddae8aee851252e4d280a198458e410613d8bf5b9cd24a800438f4616\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/92/c2/a0/8f21a00311ab2a1900b79396d87decfe65f97c7eead525854f\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.2-cp313-cp313-linux_x86_64.whl size=29584984 sha256=c691f301d1abb79e0de01f8d076f3f80d65f1a26a660b62186f8c99db4b628bc\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/c9/15/32/8370c1b87f23602d92aa9dd11d143dee8df8b5fc2fdbf2b40b\n",
      "  Building wheel for fastparquet (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastparquet: filename=fastparquet-0.8.3-cp313-cp313-linux_x86_64.whl size=1780804 sha256=e69369065fdac3d6d8c9165f3fdc355eb4c31fddd6d21e3ce01a6e98a2961ace\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/3d/0b/ee/f669dc267c36337e2a47a4b7d3903314e73d7f14f7427784bc\n",
      "  Building wheel for pyreaddbc (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyreaddbc: filename=pyreaddbc-1.2.0-cp313-cp313-manylinux_2_31_x86_64.whl size=108602 sha256=83560b07958b442781cce01c77781311248563d88ee262fbc81264df9a61e2a3\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/9d/83/bc/42e1143e4f8d155c60d0773cd197a7231ecf80b90e7731f0d5\n",
      "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9685 sha256=21cfbbe09ddf27a319a7f629a2218f25d99e573005876c72265287150d0b3859\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/8a/b8/04/0c88fb22489b0c049bee4e977c5689c7fe597d6c4b0e7d0b6a\n",
      "Successfully built cffi numpy fastparquet pyreaddbc wget\n",
      "Installing collected packages: wget, dbfread, urllib3, Unidecode, tzlocal, typing-extensions, tqdm, regex, python-dateutil, pycparser, numpy, loguru, humanize, bigtree, aioftp, urwid, elasticsearch, dateparser, cffi, pyreaddbc, fastparquet, pysus\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.22\n",
      "    Uninstalling pycparser-2.22:\n",
      "      Successfully uninstalled pycparser-2.22\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.17.1\n",
      "    Uninstalling cffi-1.17.1:\n",
      "      Successfully uninstalled cffi-1.17.1\n",
      "  Attempting uninstall: fastparquet\n",
      "    Found existing installation: fastparquet 2024.11.0\n",
      "    Uninstalling fastparquet-2024.11.0:\n",
      "      Successfully uninstalled fastparquet-2024.11.0\n",
      "Successfully installed Unidecode-1.3.8 aioftp-0.21.4 bigtree-0.12.5 cffi-1.15.1 dateparser-1.2.1 dbfread-2.0.7 elasticsearch-7.16.2 fastparquet-0.8.3 humanize-4.11.0 loguru-0.6.0 numpy-1.26.2 pycparser-2.21 pyreaddbc-1.2.0 pysus-0.11.0 python-dateutil-2.8.2 regex-2024.11.6 tqdm-4.64.0 typing-extensions-4.12.2 tzlocal-5.3 urllib3-1.26.20 urwid-2.6.16 wget-3.2\n",
      "Requirement already satisfied: gdown in /usr/local/python/3.13.1/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.13/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/python/3.13.1/lib/python3.13/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /home/codespace/.local/lib/python3.13/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.13.1/lib/python3.13/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.13/site-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.13/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from requests[socks]->gdown) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.13/site-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Collecting pylance\n",
      "  Downloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pyarrow>=14 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from pylance) (19.0.0)\n",
      "Requirement already satisfied: numpy>=1.22 in /usr/local/python/3.13.1/lib/python3.13/site-packages (from pylance) (1.26.2)\n",
      "Downloading pylance-0.23.0-cp39-abi3-manylinux_2_28_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pylance\n",
      "Successfully installed pylance-0.23.0\n",
      "Requirement already satisfied: tabulate in /usr/local/python/3.13.1/lib/python3.13/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "# Costuma ser exigida a instalação destas bibliotecas no primeiro acesso ao Pysus\n",
    "!apt-get update  \n",
    "!apt-get install libffi-dev  # Install libffi-dev\n",
    "!pip install --upgrade pip  # Ensure pip is up to date\n",
    "!pip install pysus # Exa\n",
    "!pip install gdown\n",
    "!pip install pylance\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar biblioteca básicas para manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sidrapy\n",
    "import requests # para carga de endereços web - api\n",
    "import gdown\n",
    "import openpyxl\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas para carga dos dados\n",
    "import pysus\n",
    "# import pylance\n",
    "from pysus import SIM\n",
    "from pysus.online_data.SIM import download\n",
    "from pysus.preprocessing.decoders import translate_variables_SIM\n",
    "from pysus.preprocessing.SIM import group_and_count, redistribute_missing, redistribute_cid_chapter\n",
    "from pysus.online_data.SIM import get_CID9_table, get_CID10_table, get_municipios, get_ocupations\n",
    "from ftplib import FTP\n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m ==> Este texto será impresso em amarelo!\u001b[0m\n",
      "Este em normal!\n"
     ]
    }
   ],
   "source": [
    "# Para organizar resultados, gerar prints em amarelo\n",
    "\n",
    "def print_y(text):\n",
    "  \"\"\"Imprime o texto fornecido na cor amarela.\n",
    "\n",
    "  Args:\n",
    "    text: O texto a ser impresso.\n",
    "  \"\"\"\n",
    "  print(f\"\\033[33m ==> {text}\\033[0m\")\n",
    "\n",
    "# Exemplo de uso:\n",
    "print_y(\"Este texto será impresso em amarelo!\")\n",
    "print(\"Este em normal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diretórios - configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir diretório padrão para pysus\n",
    "pysus.online_data.SIM.CACHEPATH=\"./files_in_sim\"\n",
    "# Definir pasta para download de arquivos csv e parquet\n",
    "import os \n",
    "\n",
    "# Define diretório para armazenar arquivos do sim (carregados por pysus) quando o SIM.CACHEPATH não funcionar\n",
    "os.makedirs('files_in_sim', exist_ok=True)  \n",
    "downloads_sim = \"downloads_sim_original\"\n",
    "\n",
    "# Define diretório para armazenar outros arquivos\n",
    "os.makedirs('files_in_geral', exist_ok=True)  \n",
    "\n",
    "# Define diretório para armazenar arquivos temporários\n",
    "os.makedirs('files_temp', exist_ok=True) \n",
    "\n",
    "# Define diretório para exportar arquivos finais ou de relatórios\n",
    "os.makedirs('files_out', exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acesso ao SIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = SIM().load() # Loads the files from DATASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(/dissemin/publicos/SIM/CID10/DORES, /dissemin/publicos/SIM/CID9/DORES)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CID10': 'DO', 'CID9': 'DOR'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivo principal - DO\n",
    "\n",
    "DO - Declaração de Óbito, conforme acessado no SIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga SIM principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DOTO2010.parquet: 100%|██████████| 16.6k/16.6k [00:00<00:00, 51.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados do SIM para o ano de 2010\n",
    "# Definição de variáveis\n",
    "grupo = \"CID10\" # Agrupamento por CID10\n",
    "uf = \"\" # A sigla BR carrega dados de todos as unidades federativas\n",
    "ano = [2010] # Anos do escopo, 2010 e 2022\n",
    "local = downloads_sim # Local para armazenar os arquivos, definido nas etapas anteriores\n",
    "\n",
    "# sim.get_files(\"CID10\", uf=\"BR\", year=2010)\n",
    "dobr_2010 = download(grupo,uf,ano,downloads_sim) # Carrega os dados do SIM\n",
    "# dobr2010 = download(\"CID10\",\"BR\",2010,'TESTE_EXCLUIR') # Carrega os dados do SIM\n",
    "# dobr2010 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Carrega os dados do SIM para os demais anos\n",
    "# Definição de variáveis\n",
    "grupo = \"CID10\" # Agrupamento por CID10\n",
    "uf = \"BR\" # A sigla BR carrega dados de todos as unidades federativas\n",
    "ano = [2019,2020,2021,2022] # Anos do escopo, 2010 e 2022\n",
    "local = downloads_sim # Local para armazenar os arquivos, definido nas etapas anteriores\n",
    "\n",
    "# sim.get_files(\"CID10\", uf=\"BR\", year=2010)\n",
    "dobr2010 = download(grupo,uf,ano,downloads_sim) # Carrega os dados do SIM\n",
    "# dobr2010 = download(\"CID10\",\"BR\",2010,'TESTE_EXCLUIR') # Carrega os dados do SIM\n",
    "# dobr2010 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodf = dobr.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento do arquivo principal\n",
    "\n",
    "O dicionário do SIM está em \"./Estrutura_SIM_para_CD.pdf\"\n",
    "\n",
    "Trabalhamos o CID presente no campo CAUSABAS.\n",
    "\n",
    "Em razão do escopo da População Estimada (que apresenta dados por Município, mas não de outras variáveis de desigualdade) a primeira versão será um recorte da base DOBR com os dados de CID ('CAUSABAS'), idade (a partir do tratamento de 'DTNASC'), e de Município (a partir do tratamento de 'CODMUNRES').\n",
    "\n",
    "Por se tratar de doenças evitáveis, o primeiro filtro a ser feito é com base na idade de óbito, que deve ser abaixo de 75 anos.\n",
    "\n",
    "A idade de óbito está presente no campo IDADE. Ela é composta de 3 dígitos, o primeiro identifica se a contagem é por dias(1), semanas(2), meses (3), ano (4), mais de 100 anos (5).\n",
    "\n",
    "Em razão disto, vamos desconsiderar todos os valores de dígito 4 e mais de 75 (475).\n",
    "\n",
    "\n",
    "Iremos tratar do arquivo de 2010 separado dos outros anos pela especificade daquele arquivo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1136947 entries, 0 to 1136946\n",
      "Data columns (total 60 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   CONTADOR    1133938 non-null  object\n",
      " 1   ORIGEM      1136947 non-null  object\n",
      " 2   TIPOBITO    1136947 non-null  object\n",
      " 3   DTOBITO     1136947 non-null  object\n",
      " 4   HORAOBITO   1136947 non-null  object\n",
      " 5   NATURAL     1136947 non-null  object\n",
      " 6   DTNASC      1136947 non-null  object\n",
      " 7   IDADE       1136947 non-null  object\n",
      " 8   SEXO        1136947 non-null  object\n",
      " 9   RACACOR     1136947 non-null  object\n",
      " 10  ESTCIV      1136947 non-null  object\n",
      " 11  ESC         1136947 non-null  object\n",
      " 12  OCUP        1136947 non-null  object\n",
      " 13  CODMUNRES   1136947 non-null  object\n",
      " 14  CODBAIRES   1136947 non-null  object\n",
      " 15  LOCOCOR     1136947 non-null  object\n",
      " 16  CODESTAB    1136947 non-null  object\n",
      " 17  CODMUNOCOR  1136947 non-null  object\n",
      " 18  CODBAIOCOR  1136947 non-null  object\n",
      " 19  IDADEMAE    1136947 non-null  object\n",
      " 20  ESCMAE      1136947 non-null  object\n",
      " 21  OCUPMAE     1136947 non-null  object\n",
      " 22  QTDFILVIVO  1136947 non-null  object\n",
      " 23  QTDFILMORT  1136947 non-null  object\n",
      " 24  GRAVIDEZ    1136947 non-null  object\n",
      " 25  GESTACAO    1136947 non-null  object\n",
      " 26  PARTO       1136947 non-null  object\n",
      " 27  OBITOPARTO  1136947 non-null  object\n",
      " 28  PESO        1136947 non-null  object\n",
      " 29  OBITOGRAV   1136947 non-null  object\n",
      " 30  OBITOPUERP  1136947 non-null  object\n",
      " 31  ASSISTMED   1136947 non-null  object\n",
      " 32  EXAME       1136947 non-null  object\n",
      " 33  CIRURGIA    1136947 non-null  object\n",
      " 34  NECROPSIA   1136947 non-null  object\n",
      " 35  LINHAA      1136947 non-null  object\n",
      " 36  LINHAB      1136947 non-null  object\n",
      " 37  LINHAC      1136947 non-null  object\n",
      " 38  LINHAD      1136947 non-null  object\n",
      " 39  LINHAII     1136947 non-null  object\n",
      " 40  CAUSABAS    1136947 non-null  object\n",
      " 41  DTATESTADO  1136947 non-null  object\n",
      " 42  CIRCOBITO   1136947 non-null  object\n",
      " 43  ACIDTRAB    1136947 non-null  object\n",
      " 44  FONTE       1136947 non-null  object\n",
      " 45  TPPOS       1136947 non-null  object\n",
      " 46  DTINVESTIG  1136947 non-null  object\n",
      " 47  CAUSABAS_O  1136947 non-null  object\n",
      " 48  DTCADASTRO  1136947 non-null  object\n",
      " 49  ATESTANTE   1136947 non-null  object\n",
      " 50  FONTEINV    1136947 non-null  object\n",
      " 51  DTRECEBIM   1136947 non-null  object\n",
      " 52  UFINFORM    1136947 non-null  object\n",
      " 53  CB_PRE      1136947 non-null  object\n",
      " 54  MORTEPARTO  1136947 non-null  object\n",
      " 55  DTCADINF    1136947 non-null  object\n",
      " 56  TPOBITOCOR  1136947 non-null  object\n",
      " 57  DTCADINV    1136947 non-null  object\n",
      " 58  contador    3009 non-null     object\n",
      " 59  NUMERODN    3009 non-null     object\n",
      "dtypes: object(60)\n",
      "memory usage: 520.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Acessar os dados do SIM de 2010 como 1 dataframe\n",
    "\n",
    "# Definir o diretório onde os arquivos estão localizados\n",
    "directory = 'files_in_sim'\n",
    "\n",
    "# Listar todos os arquivos na pasta\n",
    "file_list = os.listdir(directory)\n",
    "\n",
    "# Filtrar apenas os arquivos parquet\n",
    "parquet_files = [file for file in file_list if file.endswith('2010.parquet')]\n",
    "\n",
    "# Inicializar uma lista para armazenar os dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre os arquivos parquet e ler cada um em um dataframe\n",
    "for file in parquet_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_parquet(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os dataframes em um único dataframe\n",
    "dobr_10_temp = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Exibir informações do dataframe combinado\n",
    "dobr_10_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136947"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluir valores nulos da coluna CAUSABAS\n",
    "dobr_10_temp01 = dobr_10_temp.dropna(subset=['CAUSABAS'])\n",
    "dobr_10_temp01.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTADOR</th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>TIPOBITO</th>\n",
       "      <th>DTOBITO</th>\n",
       "      <th>HORAOBITO</th>\n",
       "      <th>NATURAL</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>...</th>\n",
       "      <th>DTRECEBIM</th>\n",
       "      <th>UFINFORM</th>\n",
       "      <th>CB_PRE</th>\n",
       "      <th>MORTEPARTO</th>\n",
       "      <th>DTCADINF</th>\n",
       "      <th>TPOBITOCOR</th>\n",
       "      <th>DTCADINV</th>\n",
       "      <th>contador</th>\n",
       "      <th>NUMERODN</th>\n",
       "      <th>OBITO_SOMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28042010</td>\n",
       "      <td>0500</td>\n",
       "      <td></td>\n",
       "      <td>09031925</td>\n",
       "      <td>485</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>08102010</td>\n",
       "      <td></td>\n",
       "      <td>I64</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13042010</td>\n",
       "      <td>0800</td>\n",
       "      <td></td>\n",
       "      <td>30031966</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>05052010</td>\n",
       "      <td></td>\n",
       "      <td>I461</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11032010</td>\n",
       "      <td>0815</td>\n",
       "      <td>815</td>\n",
       "      <td>12071913</td>\n",
       "      <td>496</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>22122010</td>\n",
       "      <td></td>\n",
       "      <td>R99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22082010</td>\n",
       "      <td>2230</td>\n",
       "      <td>815</td>\n",
       "      <td>25031970</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>02092010</td>\n",
       "      <td></td>\n",
       "      <td>X959</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28112010</td>\n",
       "      <td>1250</td>\n",
       "      <td></td>\n",
       "      <td>27091963</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>27012011</td>\n",
       "      <td></td>\n",
       "      <td>R99</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CONTADOR  ORIGEM  TIPOBITO   DTOBITO  HORAOBITO  NATURAL    DTNASC  IDADE  \\\n",
       "0  1         1       2         28042010  0500                09031925  485     \n",
       "1  2         1       2         13042010  0800                30031966  444     \n",
       "2  3         1       2         11032010  0815       815      12071913  496     \n",
       "3  4         1       2         22082010  2230       815      25031970  440     \n",
       "4  5         1       2         28112010  1250                27091963  447     \n",
       "\n",
       "   SEXO  RACACOR  ...  DTRECEBIM  UFINFORM  CB_PRE  MORTEPARTO  DTCADINF  \\\n",
       "0  2     4        ...  08102010             I64                            \n",
       "1  1     4        ...  05052010             I461                           \n",
       "2  2     4        ...  22122010             R99                            \n",
       "3  1     4        ...  02092010             X959                           \n",
       "4  1     4        ...  27012011             R99                            \n",
       "\n",
       "   TPOBITOCOR  DTCADINV contador NUMERODN OBITO_SOMA  \n",
       "0                            NaN      NaN          1  \n",
       "1                            NaN      NaN          2  \n",
       "2                            NaN      NaN          3  \n",
       "3                            NaN      NaN          4  \n",
       "4                            NaN      NaN          5  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar nova coluna 'OBITO_SOMA'\n",
    "dobr_10_temp01['OBITO_SOMA'] = np.where(dobr_10_temp01['CONTADOR'].isna(), dobr_10_temp01['contador'], dobr_10_temp01['CONTADOR']).astype(int)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame para verificar a nova coluna\n",
    "dobr_10_temp01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1136947 entries, 0 to 1136946\n",
      "Data columns (total 61 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   CONTADOR    1133938 non-null  object\n",
      " 1   ORIGEM      1136947 non-null  object\n",
      " 2   TIPOBITO    1136947 non-null  object\n",
      " 3   DTOBITO     1136947 non-null  object\n",
      " 4   HORAOBITO   1136947 non-null  object\n",
      " 5   NATURAL     1136947 non-null  object\n",
      " 6   DTNASC      1136947 non-null  object\n",
      " 7   IDADE       1136947 non-null  object\n",
      " 8   SEXO        1136947 non-null  object\n",
      " 9   RACACOR     1136947 non-null  object\n",
      " 10  ESTCIV      1136947 non-null  object\n",
      " 11  ESC         1136947 non-null  object\n",
      " 12  OCUP        1136947 non-null  object\n",
      " 13  CODMUNRES   1136947 non-null  object\n",
      " 14  CODBAIRES   1136947 non-null  object\n",
      " 15  LOCOCOR     1136947 non-null  object\n",
      " 16  CODESTAB    1136947 non-null  object\n",
      " 17  CODMUNOCOR  1136947 non-null  object\n",
      " 18  CODBAIOCOR  1136947 non-null  object\n",
      " 19  IDADEMAE    1136947 non-null  object\n",
      " 20  ESCMAE      1136947 non-null  object\n",
      " 21  OCUPMAE     1136947 non-null  object\n",
      " 22  QTDFILVIVO  1136947 non-null  object\n",
      " 23  QTDFILMORT  1136947 non-null  object\n",
      " 24  GRAVIDEZ    1136947 non-null  object\n",
      " 25  GESTACAO    1136947 non-null  object\n",
      " 26  PARTO       1136947 non-null  object\n",
      " 27  OBITOPARTO  1136947 non-null  object\n",
      " 28  PESO        1136947 non-null  object\n",
      " 29  OBITOGRAV   1136947 non-null  object\n",
      " 30  OBITOPUERP  1136947 non-null  object\n",
      " 31  ASSISTMED   1136947 non-null  object\n",
      " 32  EXAME       1136947 non-null  object\n",
      " 33  CIRURGIA    1136947 non-null  object\n",
      " 34  NECROPSIA   1136947 non-null  object\n",
      " 35  LINHAA      1136947 non-null  object\n",
      " 36  LINHAB      1136947 non-null  object\n",
      " 37  LINHAC      1136947 non-null  object\n",
      " 38  LINHAD      1136947 non-null  object\n",
      " 39  LINHAII     1136947 non-null  object\n",
      " 40  CAUSABAS    1136947 non-null  object\n",
      " 41  DTATESTADO  1136947 non-null  object\n",
      " 42  CIRCOBITO   1136947 non-null  object\n",
      " 43  ACIDTRAB    1136947 non-null  object\n",
      " 44  FONTE       1136947 non-null  object\n",
      " 45  TPPOS       1136947 non-null  object\n",
      " 46  DTINVESTIG  1136947 non-null  object\n",
      " 47  CAUSABAS_O  1136947 non-null  object\n",
      " 48  DTCADASTRO  1136947 non-null  object\n",
      " 49  ATESTANTE   1136947 non-null  object\n",
      " 50  FONTEINV    1136947 non-null  object\n",
      " 51  DTRECEBIM   1136947 non-null  object\n",
      " 52  UFINFORM    1136947 non-null  object\n",
      " 53  CB_PRE      1136947 non-null  object\n",
      " 54  MORTEPARTO  1136947 non-null  object\n",
      " 55  DTCADINF    1136947 non-null  object\n",
      " 56  TPOBITOCOR  1136947 non-null  object\n",
      " 57  DTCADINV    1136947 non-null  object\n",
      " 58  contador    3009 non-null     object\n",
      " 59  NUMERODN    3009 non-null     object\n",
      " 60  OBITO_SOMA  1136947 non-null  int64 \n",
      "dtypes: int64(1), object(60)\n",
      "memory usage: 529.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dobr_10_temp01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela : 1134923\n",
      "Contador de óbitos : 1136947\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n",
      "|    |   DTOBITO | CAUSABAS   |   CODMUNRES |   IDADE |   SEXO |   RACACOR |   OBITO_SOMA |\n",
      "|----+-----------+------------+-------------+---------+--------+-----------+--------------|\n",
      "|  0 |  01012010 | A060       |   231380    |   432   |   1    |   4       |            1 |\n",
      "|  1 |  01012010 | A09        |   210340    |   401   |   2    |   4       |            1 |\n",
      "|  2 |  01012010 | A09        |   220500    |   493   |   1    |   4       |            1 |\n",
      "|  3 |  01012010 | A09        |   220770    |   468   |   2    |   2       |            1 |\n",
      "|  4 |  01012010 | A09        |   220780    |   489   |   1    |   1       |            1 |\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Agrupar dobr_10_temp02 por 'DTOBITO', 'CAUSABAS', 'CODMUNRES', 'IDADE', 'SEXO', 'RACACOR' e somar 'CONTADOR'\n",
    "dobr_10_temp02 = dobr_10_temp01.groupby(['DTOBITO', 'CAUSABAS', 'CODMUNRES', 'IDADE', 'SEXO', 'RACACOR'])['OBITO_SOMA'].count().reset_index()\n",
    "\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = dobr_10_temp02\n",
    "print(f'Registro da tabela : {tab.shape[0]}')\n",
    "print(f'Contador de óbitos : {tab.OBITO_SOMA.sum()}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql', maxcolwidths=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1134923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arquivo para doenças evitáveis - excluir maiores de 74 anos\n",
    "dobr_10_temp03 = dobr_10_temp02.copy()\n",
    "\n",
    "# Substituir valores '     ' e '-' por '0' na coluna IDADE\n",
    "dobr_10_temp03['IDADE'] = dobr_10_temp03['IDADE'].replace(['     '], '0')\n",
    "\n",
    "# transformar IDADE em inteiro e excluir valores maiores que 474\n",
    "dobr_10_temp03['IDADE'] = dobr_10_temp03['IDADE'].astype(int)\n",
    "\n",
    "dobr_10_temp03.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela : 721140\n",
      "Contador de óbitos : 722229\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n",
      "|    |   DTOBITO | CAUSABAS   |   CODMUNRES |   IDADE |   SEXO |   RACACOR |   OBITO_SOMA |\n",
      "|----+-----------+------------+-------------+---------+--------+-----------+--------------|\n",
      "|  0 |  01012010 | A060       |   231380    |     432 |   1    |   4       |            1 |\n",
      "|  1 |  01012010 | A09        |   210340    |     401 |   2    |   4       |            1 |\n",
      "|  2 |  01012010 | A09        |   220770    |     468 |   2    |   2       |            1 |\n",
      "|  3 |  01012010 | A09        |   290080    |     401 |   1    |   4       |            1 |\n",
      "|  4 |  01012010 | A09        |   290320    |     307 |   1    |   4       |            1 |\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Filtrar as idades menores de 75\n",
    "dobr_10_temp04 = dobr_10_temp03[dobr_10_temp03['IDADE'] < 475].reset_index(drop=True)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = dobr_10_temp04\n",
    "print(f'Registro da tabela : {tab.shape[0]}')\n",
    "print(f'Contador de óbitos : {tab.OBITO_SOMA.sum()}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql', maxcolwidths=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvamento provisório\n",
    "# dobr_19a22_temp01.to_parquet('dobr_19a22_temp01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e tratar arquivos de DO de outros anos\n",
    "\n",
    "# Read the parquet files\n",
    "dobr2019 = pd.read_parquet('files_in_sim/DOBR2019.parquet')\n",
    "dobr2020 = pd.read_parquet('files_in_sim/DOBR2020.parquet')\n",
    "dobr2021 = pd.read_parquet('files_in_sim/DOBR2021.parquet')\n",
    "dobr2022 = pd.read_parquet('files_in_sim/DOBR2022.parquet')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "dobr_19a22_temp = pd.concat([dobr2019,dobr2020,dobr2021,dobr2022], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6283540 entries, 0 to 6283539\n",
      "Data columns (total 87 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   ORIGEM      object\n",
      " 1   TIPOBITO    object\n",
      " 2   DTOBITO     object\n",
      " 3   HORAOBITO   object\n",
      " 4   NATURAL     object\n",
      " 5   CODMUNNATU  object\n",
      " 6   DTNASC      object\n",
      " 7   IDADE       object\n",
      " 8   SEXO        object\n",
      " 9   RACACOR     object\n",
      " 10  ESTCIV      object\n",
      " 11  ESC         object\n",
      " 12  ESC2010     object\n",
      " 13  SERIESCFAL  object\n",
      " 14  OCUP        object\n",
      " 15  CODMUNRES   object\n",
      " 16  LOCOCOR     object\n",
      " 17  CODESTAB    object\n",
      " 18  ESTABDESCR  object\n",
      " 19  CODMUNOCOR  object\n",
      " 20  IDADEMAE    object\n",
      " 21  ESCMAE      object\n",
      " 22  ESCMAE2010  object\n",
      " 23  SERIESCMAE  object\n",
      " 24  OCUPMAE     object\n",
      " 25  QTDFILVIVO  object\n",
      " 26  QTDFILMORT  object\n",
      " 27  GRAVIDEZ    object\n",
      " 28  SEMAGESTAC  object\n",
      " 29  GESTACAO    object\n",
      " 30  PARTO       object\n",
      " 31  OBITOPARTO  object\n",
      " 32  PESO        object\n",
      " 33  TPMORTEOCO  object\n",
      " 34  OBITOGRAV   object\n",
      " 35  OBITOPUERP  object\n",
      " 36  ASSISTMED   object\n",
      " 37  EXAME       object\n",
      " 38  CIRURGIA    object\n",
      " 39  NECROPSIA   object\n",
      " 40  LINHAA      object\n",
      " 41  LINHAB      object\n",
      " 42  LINHAC      object\n",
      " 43  LINHAD      object\n",
      " 44  LINHAII     object\n",
      " 45  CAUSABAS    object\n",
      " 46  CB_PRE      object\n",
      " 47  COMUNSVOIM  object\n",
      " 48  DTATESTADO  object\n",
      " 49  CIRCOBITO   object\n",
      " 50  ACIDTRAB    object\n",
      " 51  FONTE       object\n",
      " 52  NUMEROLOTE  object\n",
      " 53  TPPOS       object\n",
      " 54  DTINVESTIG  object\n",
      " 55  CAUSABAS_O  object\n",
      " 56  DTCADASTRO  object\n",
      " 57  ATESTANTE   object\n",
      " 58  STCODIFICA  object\n",
      " 59  CODIFICADO  object\n",
      " 60  VERSAOSIST  object\n",
      " 61  VERSAOSCB   object\n",
      " 62  FONTEINV    object\n",
      " 63  DTRECEBIM   object\n",
      " 64  ATESTADO    object\n",
      " 65  DTRECORIGA  object\n",
      " 66  CAUSAMAT    object\n",
      " 67  ESCMAEAGR1  object\n",
      " 68  ESCFALAGR1  object\n",
      " 69  STDOEPIDEM  object\n",
      " 70  STDONOVA    object\n",
      " 71  DIFDATA     object\n",
      " 72  NUDIASOBCO  object\n",
      " 73  NUDIASOBIN  object\n",
      " 74  DTCADINV    object\n",
      " 75  TPOBITOCOR  object\n",
      " 76  DTCONINV    object\n",
      " 77  FONTES      object\n",
      " 78  TPRESGINFO  object\n",
      " 79  TPNIVELINV  object\n",
      " 80  NUDIASINF   object\n",
      " 81  DTCADINF    object\n",
      " 82  MORTEPARTO  object\n",
      " 83  DTCONCASO   object\n",
      " 84  FONTESINF   object\n",
      " 85  ALTCAUSA    object\n",
      " 86  CONTADOR    object\n",
      "dtypes: object(87)\n",
      "memory usage: 4.1+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGEM</th>\n",
       "      <th>TIPOBITO</th>\n",
       "      <th>DTOBITO</th>\n",
       "      <th>HORAOBITO</th>\n",
       "      <th>NATURAL</th>\n",
       "      <th>CODMUNNATU</th>\n",
       "      <th>DTNASC</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>RACACOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FONTES</th>\n",
       "      <th>TPRESGINFO</th>\n",
       "      <th>TPNIVELINV</th>\n",
       "      <th>NUDIASINF</th>\n",
       "      <th>DTCADINF</th>\n",
       "      <th>MORTEPARTO</th>\n",
       "      <th>DTCONCASO</th>\n",
       "      <th>FONTESINF</th>\n",
       "      <th>ALTCAUSA</th>\n",
       "      <th>CONTADOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21062019</td>\n",
       "      <td>0230</td>\n",
       "      <td>829</td>\n",
       "      <td>292990</td>\n",
       "      <td>12041941</td>\n",
       "      <td>478</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>950245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01052019</td>\n",
       "      <td>1327</td>\n",
       "      <td>829</td>\n",
       "      <td>292740</td>\n",
       "      <td>22061956</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>950246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16052019</td>\n",
       "      <td>1855</td>\n",
       "      <td>829</td>\n",
       "      <td>292260</td>\n",
       "      <td>05041940</td>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>950247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>03052019</td>\n",
       "      <td>0640</td>\n",
       "      <td>831</td>\n",
       "      <td>317010</td>\n",
       "      <td>18051950</td>\n",
       "      <td>468</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>950248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26062019</td>\n",
       "      <td>0840</td>\n",
       "      <td>850</td>\n",
       "      <td>500630</td>\n",
       "      <td>13061959</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>950249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGEM TIPOBITO   DTOBITO HORAOBITO NATURAL CODMUNNATU    DTNASC IDADE SEXO  \\\n",
       "0      1        2  21062019     0230      829    292990   12041941   478    2   \n",
       "1      1        2  01052019     1327      829    292740   22061956   462    1   \n",
       "2      1        2  16052019     1855      829    292260   05041940   479    2   \n",
       "3      1        2  03052019     0640      831    317010   18051950   468    2   \n",
       "4      1        2  26062019     0840      850    500630   13061959   460    1   \n",
       "\n",
       "  RACACOR  ...  FONTES TPRESGINFO TPNIVELINV NUDIASINF  DTCADINF MORTEPARTO  \\\n",
       "0       2  ...                                                                \n",
       "1       2  ...                                                                \n",
       "2       5  ...                                                                \n",
       "3       1  ...                                                                \n",
       "4       1  ...                                                                \n",
       "\n",
       "  DTCONCASO FONTESINF ALTCAUSA  CONTADOR  \n",
       "0                               950245    \n",
       "1                               950246    \n",
       "2                               950247    \n",
       "3                               950248    \n",
       "4                               950249    \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dobr_19a22_temp.info())\n",
    "dobr_19a22_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6283540"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar campos\n",
    "dobr_19a22_temp01 = dobr_19a22_temp[['DTOBITO','CAUSABAS', 'CODMUNRES','IDADE','SEXO','RACACOR','CONTADOR']]\n",
    "\n",
    "dobr_19a22_temp01.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6283540"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contador_nulo = dobr_19a22_temp01.CONTADOR.count()\n",
    "contador_nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela : 6252305\n",
      "Contador de óbitos : 6283540\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n",
      "|    |   DTOBITO | CAUSABAS   |   CODMUNRES |   IDADE |   SEXO |   RACACOR |   OBITO_SOMA |\n",
      "|----+-----------+------------+-------------+---------+--------+-----------+--------------|\n",
      "|  0 |  01012019 | A049       |     210820  |     477 |      2 |         4 |            1 |\n",
      "|  1 |  01012019 | A049       |     355080  |     452 |      1 |         1 |            1 |\n",
      "|  2 |  01012019 | A09        |     150553  |     479 |      1 |         4 |            1 |\n",
      "|  3 |  01012019 | A09        |     310620  |     478 |      2 |         4 |            1 |\n",
      "|  4 |  01012019 | A09        |     320520  |     467 |      1 |         1 |            1 |\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Agrupar dobr_10_temp02 por 'DTOBITO', 'CAUSABAS', 'CODMUNRES', 'IDADE', 'SEXO', 'RACACOR' e somar 'CONTADOR'\n",
    "dobr_19a22_temp02 = dobr_19a22_temp01.groupby(['DTOBITO', 'CAUSABAS', 'CODMUNRES', 'IDADE', 'SEXO', 'RACACOR'])['CONTADOR'].count().reset_index()\n",
    "\n",
    "dobr_19a22_temp02.rename(columns={'CONTADOR':'OBITO_SOMA'} , inplace=True)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = dobr_19a22_temp02\n",
    "print(f'Registro da tabela : {tab.shape[0]}')\n",
    "print(f'Contador de óbitos : {tab.OBITO_SOMA.sum()}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql', maxcolwidths=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna DTOBITO tem 0 valores nulos\n",
      "Coluna CAUSABAS tem 0 valores nulos\n",
      "Coluna CODMUNRES tem 0 valores nulos\n",
      "Coluna IDADE tem 0 valores nulos\n",
      "Coluna SEXO tem 0 valores nulos\n",
      "Coluna RACACOR tem 0 valores nulos\n",
      "Coluna OBITO_SOMA tem 0 valores nulos\n"
     ]
    }
   ],
   "source": [
    "columns = dobr_19a22_temp02.columns\n",
    "\n",
    "for column in columns:\n",
    "    count_nulo = dobr_19a22_temp02[column].isna().sum()\n",
    "    print(f\"Coluna {column} tem {count_nulo} valores nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar IDADE em inteiro \n",
    "dobr_19a22_temp03 = dobr_19a22_temp02.copy()\n",
    "dobr_19a22_temp03['IDADE'] = dobr_19a22_temp03['IDADE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela : 3706335\n",
      "Contador de óbitos : 3724693\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n",
      "|    |   DTOBITO | CAUSABAS   |   CODMUNRES |   IDADE |   SEXO |   RACACOR |   OBITO_SOMA |\n",
      "|----+-----------+------------+-------------+---------+--------+-----------+--------------|\n",
      "|  1 |  01012019 | A049       |     355080  |     452 |      1 |         1 |            1 |\n",
      "|  4 |  01012019 | A09        |     320520  |     467 |      1 |         1 |            1 |\n",
      "|  5 |  01012019 | A09        |     330040  |     472 |      1 |         1 |            1 |\n",
      "|  7 |  01012019 | A09        |     350970  |     460 |      1 |         4 |            1 |\n",
      "|  9 |  01012019 | A09        |     355100  |     452 |      2 |         1 |            1 |\n",
      "+----+-----------+------------+-------------+---------+--------+-----------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Excluir valores maiores que 474\n",
    "dobr_19a22_temp04 = dobr_19a22_temp03[dobr_19a22_temp03['IDADE'] < 475]\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = dobr_19a22_temp04\n",
    "print(f'Registro da tabela : {tab.shape[0]}')\n",
    "print(f'Contador de óbitos : {tab.OBITO_SOMA.sum()}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql', maxcolwidths=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Carga provisória\n",
    "# dobr_19a22_temp04.to_parquet('dobr_19a22_temp04.parquet')\n",
    "# dobr_10_temp04 = pd.read_parquet('dobr_10_temp04.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4427475 entries, 0 to 4427474\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   DTOBITO     object\n",
      " 1   CAUSABAS    object\n",
      " 2   CODMUNRES   object\n",
      " 3   IDADE       int64 \n",
      " 4   SEXO        object\n",
      " 5   RACACOR     object\n",
      " 6   OBITO_SOMA  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 236.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the dataframes\n",
    "dobr_10_19a22_temp = pd.concat([dobr_19a22_temp04,dobr_10_temp04], ignore_index=True)\n",
    "dobr_10_19a22_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m ==>  O arquivo de declarações de óbito dos anos de 2010,2019,2020,2021 e 2022 tem o total de 4427475 registros \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "\n",
    "shape1 = dobr_10_19a22_temp.CAUSABAS.count()\n",
    "\n",
    "print_y(f\" O arquivo de declarações de óbito dos anos de 2010,2019,2020,2021 e 2022 tem o total de {shape1} registros \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela : 4427475\n",
      "Soma de óbitos : 4446922\n",
      "+----+------------+-------------+--------+-----------+--------------+-------------+\n",
      "|    | CAUSABAS   | CODMUNRES   |   SEXO |   RACACOR |   OBITO_SOMA | ANO_OBITO   |\n",
      "|----+------------+-------------+--------+-----------+--------------+-------------|\n",
      "|  0 | A049       | _355080     |      1 |         1 |            1 | _2019       |\n",
      "|  1 | A09        | _320520     |      1 |         1 |            1 | _2019       |\n",
      "|  2 | A09        | _330040     |      1 |         1 |            1 | _2019       |\n",
      "|  3 | A09        | _350970     |      1 |         4 |            1 | _2019       |\n",
      "|  4 | A09        | _355100     |      2 |         1 |            1 | _2019       |\n",
      "+----+------------+-------------+--------+-----------+--------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# Ajustar os campos\n",
    "dobr_10_19a22_temp01 = dobr_10_19a22_temp.copy()\n",
    "\n",
    "# assegurar CODMUNRES como string\n",
    "dobr_10_19a22_temp01['CODMUNRES'] = '_' + dobr_10_19a22_temp01['CODMUNRES'].astype(str).str[:6]\n",
    "\n",
    "# campo ano_obito formado pelos 4 últimos caracteres de DTOBITO, como número\n",
    "dobr_10_19a22_temp01['ANO_OBITO'] = '_' + dobr_10_19a22_temp01['DTOBITO'].str[-4:]\n",
    "\n",
    "# excluir colunas DTOBITO e IDADE\n",
    "dobr_10_19a22_temp02 = dobr_10_19a22_temp01.drop(['DTOBITO','IDADE'], axis=1)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = dobr_10_19a22_temp02\n",
    "print(f'Registro da tabela : {tab.shape[0]}')\n",
    "print(f'Soma de óbitos : {tab.OBITO_SOMA.sum()}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados e geração de arquivo DOBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "##########       Etapa diferenciada da versão      ##########\n",
    "\n",
    "Atenção na hora de salvar arquivo temporário com as variáveis de versão, formato e local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar arquivo em parquet\n",
    "dobr_10_19a22_temp02.to_parquet('files_in_geral/dobr_10_19a22_u75.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m ==> O número de registros de óbitos originais por ano:\n",
      "        * 2010: 1136947\n",
      "        * 2019: 1349801\n",
      "        * 2020: 1556824\n",
      "        * 2021: 1832649\n",
      "        * 2022: 1544266\n",
      "        \u001b[0m\n",
      "\u001b[33m ==> O número de registros excluídos por apresentar idade maior de 74 anos foi de 2973565 registros\u001b[0m\n",
      "\u001b[33m ==> O número de registros de óbitos resultantes é de 4446922 registros\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Contador\n",
    "\n",
    "# apresentar valor da diferença entre os números de registros de dobr e dobr_filtered\n",
    "\n",
    "shape_2010 = dobr_10_temp.shape[0]\n",
    "shape_2019 = dobr2019.shape[0]\n",
    "shape_2020 = dobr2020.shape[0]\n",
    "shape_2021 = dobr2021.shape[0]\n",
    "shape_2022 = dobr2022.shape[0]\n",
    "shape_all = shape_2010 + shape_2019 + shape_2020 + shape_2021 + shape_2022\n",
    "\n",
    "print_y(f\"\"\"O número de registros de óbitos originais por ano:\n",
    "        * 2010: {shape_2010}\n",
    "        * 2019: {shape_2019}\n",
    "        * 2020: {shape_2020}\n",
    "        * 2021: {shape_2021}\n",
    "        * 2022: {shape_2022}\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "dif = shape_all - dobr_10_19a22_temp02.shape[0]\n",
    "print(f\"\\033[33m ==> O número de registros excluídos por apresentar idade maior de 74 anos foi de {dif} registros\\033[0m\")\n",
    "print(f\"\\033[33m ==> O número de registros de óbitos resultantes é de {dobr_10_19a22_temp02.shape[0]} registros\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga SIM auxiliar\n",
    "\n",
    "O SIM traz algumas tabelas auxiliares de CID10 e municípios. \n",
    "\n",
    "Não iremos trazemos estas informações, no entanto, porque iremos utilizar dados de municípios concomitante à população do Censo do IBGE e sobre os CIDs iremos consultar a informações já da lista de doenças evitáveis, conforme OCDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download de tabela auxiliar de CID10\n",
    "# cid10 = get_CID10_table()\n",
    "# cid10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download de tabela auxiliar de CID10\n",
    "# munic = get_municipios()\n",
    "# print(munic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga externa ao SIM\n",
    "\n",
    "Iremos carregar informações de fontes externas sobre população e CIDs de doenças evitáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carga de CIDs doenças evitáveis - SVS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivos de doenças evitáveis foi tratado a partir de documento da OCDE e da SVS e será dada carga neles pelo google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download de tabela tratada de CIDs evitáveis de acordo com documentos da SVS\n",
    "\n",
    "# url = 'https://docs.google.com/spreadsheets/d/1YWurDqnBDMz4ACOEctY9uuQkEm7uSRAogzZETQrLCXk/edit?usp=drive_link'\n",
    "# # Convert the Google Sheets URL to a CSV export URL\n",
    "# csv_url = url.replace('/edit?usp=drive_link', '/export?format=csv')\n",
    "\n",
    "# # Read the CSV data into a pandas DataFrame\n",
    "# df = pd.read_csv(csv_url)\n",
    "\n",
    "# # Now you can work with the DataFrame 'df'\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Salvar arquivo csv\n",
    "# df.to_csv('downloads_outros/cid10_evit_svs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carga de CIDs doenças evitáveis - OCDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avoid_flag</th>\n",
       "      <th>prevent_flag</th>\n",
       "      <th>treat_flag</th>\n",
       "      <th>Group</th>\n",
       "      <th>Causes of deaths</th>\n",
       "      <th>Rationale for inclusion</th>\n",
       "      <th>Range</th>\n",
       "      <th>cid_pai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avoidable mortality</td>\n",
       "      <td>Preventable mortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious diseases</td>\n",
       "      <td>Intestinal diseases</td>\n",
       "      <td>Most of these infections can be prevented thro...</td>\n",
       "      <td>(A00-A09)</td>\n",
       "      <td>A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avoidable mortality</td>\n",
       "      <td>Preventable mortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious diseases</td>\n",
       "      <td>Diphtheria, Tetanus, Poliomyelitis</td>\n",
       "      <td>Most of these infections can be prevented thro...</td>\n",
       "      <td>(A35, A36, A80)</td>\n",
       "      <td>A35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avoidable mortality</td>\n",
       "      <td>Preventable mortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious diseases</td>\n",
       "      <td>Diphtheria, Tetanus, Poliomyelitis</td>\n",
       "      <td>Most of these infections can be prevented thro...</td>\n",
       "      <td>(A35, A36, A80)</td>\n",
       "      <td>A36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avoidable mortality</td>\n",
       "      <td>Preventable mortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious diseases</td>\n",
       "      <td>Diphtheria, Tetanus, Poliomyelitis</td>\n",
       "      <td>Most of these infections can be prevented thro...</td>\n",
       "      <td>(A35, A36, A80)</td>\n",
       "      <td>A80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avoidable mortality</td>\n",
       "      <td>Preventable mortality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infectious diseases</td>\n",
       "      <td>Whooping cough</td>\n",
       "      <td>Most of these infections can be prevented thro...</td>\n",
       "      <td>(A37)</td>\n",
       "      <td>A37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avoid_flag           prevent_flag treat_flag                Group  \\\n",
       "0  Avoidable mortality  Preventable mortality        NaN  Infectious diseases   \n",
       "1  Avoidable mortality  Preventable mortality        NaN  Infectious diseases   \n",
       "2  Avoidable mortality  Preventable mortality        NaN  Infectious diseases   \n",
       "3  Avoidable mortality  Preventable mortality        NaN  Infectious diseases   \n",
       "4  Avoidable mortality  Preventable mortality        NaN  Infectious diseases   \n",
       "\n",
       "                     Causes of deaths  \\\n",
       "0                 Intestinal diseases   \n",
       "1  Diphtheria, Tetanus, Poliomyelitis   \n",
       "2  Diphtheria, Tetanus, Poliomyelitis   \n",
       "3  Diphtheria, Tetanus, Poliomyelitis   \n",
       "4                      Whooping cough   \n",
       "\n",
       "                             Rationale for inclusion            Range cid_pai  \n",
       "0  Most of these infections can be prevented thro...        (A00-A09)      A0  \n",
       "1  Most of these infections can be prevented thro...  (A35, A36, A80)     A35  \n",
       "2  Most of these infections can be prevented thro...  (A35, A36, A80)     A36  \n",
       "3  Most of these infections can be prevented thro...  (A35, A36, A80)     A80  \n",
       "4  Most of these infections can be prevented thro...            (A37)     A37  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Download de tabela tratada de CIDs evitáveis de acordo com documentos da OCDE\n",
    "# url = 'https://docs.google.com/spreadsheets/d/1X8AH0zs4PNc_bUpZ3tBvFw2HGpgb9CjShOkwXQ0so_I/edit?usp=sharing'\n",
    "# # Convert the Google Sheets URL to a CSV export URL\n",
    "# csv_url = url.replace('/edit?usp=sharing', '/export?format=csv')\n",
    "\n",
    "# # Read the CSV data into a pandas DataFrame\n",
    "# ocde_evit = pd.read_csv(csv_url)\n",
    "\n",
    "# # Now you can work with the DataFrame 'df'\n",
    "# ocde_evit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346 entries, 0 to 345\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   avoid_flag               346 non-null    object\n",
      " 1   prevent_flag             189 non-null    object\n",
      " 2   treat_flag               184 non-null    object\n",
      " 3   Group                    346 non-null    object\n",
      " 4   Causes of deaths         346 non-null    object\n",
      " 5   Rationale for inclusion  346 non-null    object\n",
      " 6   Range                    346 non-null    object\n",
      " 7   cid_pai                  346 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 21.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ocde_evit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## População Censo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de População Censo \n",
    "\n",
    "\n",
    "Os dados populacionais são os dos Censos de 2010 e 2022.\n",
    "\n",
    "A fonte de dados para gerar os arquivos ou o endereço do caminho SIDRA, é https://sidra.ibge.gov.br/Tabela/9606.\n",
    "\n",
    "No caso de municípios, como coletamos variáveis de sexo, raça e faixa etária, o que excedeu os limites do uso do API do SIDRA, então iremos carregar o download feito a posteriori, via arquivo no google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# ID of the file on Google Drive\n",
    "file_id = '1-viTldhMlr7fLakBHF-3psclZjOFV3MN'\n",
    "# Output file path\n",
    "output_file = 'files_in_treat/censo_raw.zip'\n",
    "\n",
    "# Download the file\n",
    "gdown.download(id=file_id, output=output_file, quiet=False)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(output_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall('files_in_treat/unzipped_data')\n",
    "\n",
    "# Assuming the unzipped file is a CSV, read it into a DataFrame\n",
    "csv_file_path = 'files_in_treat/unzipped_data/your_csv_file.csv'\n",
    "df = pd.read_csv(csv_file_path, skiprows=3)\n",
    "\n",
    "# Save the DataFrame as a Parquet file\n",
    "df.to_parquet('files_in_treat/data.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-xByhnUTPG25EXlz2Ls2Amnxv5D0id6G\n",
      "To: /workspaces/heat_br_bloco1/files_in_treat/censo_2010_2022_raw.csv\n",
      "100%|██████████| 10.5M/10.5M [00:00<00:00, 21.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'files_in_treat/censo_2010_2022_raw.csv'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "# https://drive.google.com/file/d/1-xByhnUTPG25EXlz2Ls2Amnxv5D0id6G/view?usp=drive_link\n",
    "# ID of the file on Google Drive\n",
    "file_id = '1-xByhnUTPG25EXlz2Ls2Amnxv5D0id6G'\n",
    "# Output file path\n",
    "output_file = 'files_in_treat/censo_2010_2022_raw.csv'\n",
    "\n",
    "# Download the file\n",
    "gdown.download(id=file_id, output=output_file, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111960\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|    |   Ano | Nível   |   Cód. | Unidade da Federação e Município   | Sexo   | Cor ou raça   |   Total |   75 a 79 anos |   80 a 84 anos |   85 a 89 anos |   90 a 94 anos |   95 a 99 anos | 100 anos ou mais   |\n",
      "|----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------|\n",
      "|  0 |  2010 | UF      |     11 | Rondônia                           | Homens | Branca        |  274670 |           2808 |           1621 |            641 |            224 |             54 | 8                  |\n",
      "|  1 |  2010 | UF      |     11 | Rondônia                           | Homens | Preta         |   60563 |            672 |            365 |            181 |             68 |             19 | 6                  |\n",
      "|  2 |  2010 | UF      |     11 | Rondônia                           | Homens | Amarela       |   10126 |             67 |             44 |             19 |              8 |              2 | -                  |\n",
      "|  3 |  2010 | UF      |     11 | Rondônia                           | Homens | Parda         |  443524 |           3184 |           1859 |            743 |            252 |             65 | 20                 |\n",
      "|  4 |  2010 | UF      |     11 | Rondônia                           | Homens | Indígena      |    6143 |             44 |             24 |             25 |             10 |              3 | -                  |\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "output_file = 'files_in_treat/censo_2010_2022_raw.csv'\n",
    "censo_temp = pd.read_csv(output_file, skiprows=3, dtype=str)\n",
    "\n",
    "tab = censo_temp\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111940\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|    |   Ano | Nível   |   Cód. | Unidade da Federação e Município   | Sexo   | Cor ou raça   |   Total |   75 a 79 anos |   80 a 84 anos |   85 a 89 anos |   90 a 94 anos |   95 a 99 anos | 100 anos ou mais   |\n",
      "|----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------|\n",
      "|  0 |  2010 | UF      |     11 | Rondônia                           | Homens | Branca        |  274670 |           2808 |           1621 |            641 |            224 |             54 | 8                  |\n",
      "|  1 |  2010 | UF      |     11 | Rondônia                           | Homens | Preta         |   60563 |            672 |            365 |            181 |             68 |             19 | 6                  |\n",
      "|  2 |  2010 | UF      |     11 | Rondônia                           | Homens | Amarela       |   10126 |             67 |             44 |             19 |              8 |              2 | -                  |\n",
      "|  3 |  2010 | UF      |     11 | Rondônia                           | Homens | Parda         |  443524 |           3184 |           1859 |            743 |            252 |             65 | 20                 |\n",
      "|  4 |  2010 | UF      |     11 | Rondônia                           | Homens | Indígena      |    6143 |             44 |             24 |             25 |             10 |              3 | -                  |\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Primeira linha de tratamento para salvar arquivo\n",
    "\n",
    "# Excluir notas e comentários do arquivo\n",
    "censo_temp01 = censo_temp.dropna(subset=['Total']).reset_index(drop=True)\n",
    "\n",
    "# Renomear colunas\n",
    "censo_temp01.rename(columns={'Unidade da Federação': 'unidade_no'}, inplace=True)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame\n",
    "# censo_temp01.info()\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_temp01\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar arquivo de população do Censo\n",
    "censo_temp01.to_parquet('files_in_treat/censo_2010_2022_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de População Censo Municípios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de arquivo de População do Censo\n",
    "censo_temp01 = pd.read_parquet('files_in_geral/censo_2010_2022_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111940\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|    |   Ano | Nível   |   Cód. | Unidade da Federação e Município   | Sexo   | Cor ou raça   |   Total |   75 a 79 anos |   80 a 84 anos |   85 a 89 anos |   90 a 94 anos |   95 a 99 anos | 100 anos ou mais   |\n",
      "|----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------|\n",
      "|  0 |  2010 | UF      |     11 | Rondônia                           | Homens | Branca        |  274670 |           2808 |           1621 |            641 |            224 |             54 | 8                  |\n",
      "|  1 |  2010 | UF      |     11 | Rondônia                           | Homens | Preta         |   60563 |            672 |            365 |            181 |             68 |             19 | 6                  |\n",
      "|  2 |  2010 | UF      |     11 | Rondônia                           | Homens | Amarela       |   10126 |             67 |             44 |             19 |              8 |              2 | -                  |\n",
      "|  3 |  2010 | UF      |     11 | Rondônia                           | Homens | Parda         |  443524 |           3184 |           1859 |            743 |            252 |             65 | 20                 |\n",
      "|  4 |  2010 | UF      |     11 | Rondônia                           | Homens | Indígena      |    6143 |             44 |             24 |             25 |             10 |              3 | -                  |\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_temp01\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidades federativas do arquivo Censo_pop: ['UF' 'MU']\n",
      "Anos do arquivo Censo_pop: ['2010' '2022']\n"
     ]
    }
   ],
   "source": [
    "# Identificar a classificação de unidades federativas\n",
    "print(f'Unidades federativas do arquivo Censo_pop: {censo_temp01.Nível.unique()}')\n",
    "\n",
    "# Apresentar os anos do Censo\n",
    "print(f'Anos do arquivo Censo_pop: {censo_temp01.Ano.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111940\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n",
      "|    |   Ano | Nível   |   Cód. | Unidade da Federação e Município   | Sexo   | Cor ou raça   |   Total |   75 a 79 anos |   80 a 84 anos |   85 a 89 anos |   90 a 94 anos |   95 a 99 anos |   100 anos ou mais |\n",
      "|----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------|\n",
      "|  0 |  2010 | UF      |     11 | Rondônia                           | Homens | Branca        |  274670 |           2808 |           1621 |            641 |            224 |             54 |                  8 |\n",
      "|  1 |  2010 | UF      |     11 | Rondônia                           | Homens | Preta         |   60563 |            672 |            365 |            181 |             68 |             19 |                  6 |\n",
      "|  2 |  2010 | UF      |     11 | Rondônia                           | Homens | Amarela       |   10126 |             67 |             44 |             19 |              8 |              2 |                  0 |\n",
      "|  3 |  2010 | UF      |     11 | Rondônia                           | Homens | Parda         |  443524 |           3184 |           1859 |            743 |            252 |             65 |                 20 |\n",
      "|  4 |  2010 | UF      |     11 | Rondônia                           | Homens | Indígena      |    6143 |             44 |             24 |             25 |             10 |              3 |                  0 |\n",
      "+----+-------+---------+--------+------------------------------------+--------+---------------+---------+----------------+----------------+----------------+----------------+----------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Preparar colunas para conseguir valores da população até 74 anos\n",
    "\n",
    "# Colunas para transformar em inteiro\n",
    "cols_age = ['Total','75 a 79 anos', '80 a 84 anos', '85 a 89 anos','90 a 94 anos', '95 a 99 anos', '100 anos ou mais']\n",
    "\n",
    "# para todas as colunas identificar substituir '-' por 0\n",
    "censo_temp02 = censo_temp01.copy()\n",
    "censo_temp02[cols_age] = censo_temp02[cols_age].replace('-',0)\n",
    "\n",
    "# transformar todas as colunas definidas para formato integer\n",
    "censo_temp02[cols_age] = censo_temp02[cols_age].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_temp02\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111940\n",
      "+----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------+\n",
      "|    |   Ano | Nível   |   unidade_co | unidade_no   | Sexo   | Cor ou raça   |   pop_total |   pop_under74 |\n",
      "|----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------|\n",
      "|  0 |  2010 | UF      |           11 | Rondônia     | Homens | Branca        |      274670 |        269314 |\n",
      "|  1 |  2010 | UF      |           11 | Rondônia     | Homens | Preta         |       60563 |         59252 |\n",
      "|  2 |  2010 | UF      |           11 | Rondônia     | Homens | Amarela       |       10126 |          9986 |\n",
      "|  3 |  2010 | UF      |           11 | Rondônia     | Homens | Parda         |      443524 |        437401 |\n",
      "|  4 |  2010 | UF      |           11 | Rondônia     | Homens | Indígena      |        6143 |          6037 |\n",
      "+----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# Gerar coluna de população total até 74 anos\n",
    "cols_age_over75 = ['75 a 79 anos', '80 a 84 anos', '85 a 89 anos','90 a 94 anos', '95 a 99 anos', '100 anos ou mais']\n",
    "\n",
    "censo_temp03 = censo_temp02.copy()\n",
    "\n",
    "# Subtrair a população de 75 anos ou mais da população total\n",
    "censo_temp03['pop_under74'] = censo_temp03['Total'] - censo_temp03[cols_age_over75].sum(axis=1)\n",
    "\n",
    "# Excluir colunar cols_age_over75 e 0 a 4 anos\n",
    "censo_temp03.drop(columns=cols_age_over75, inplace=True)\n",
    "\n",
    "# Renomear coluna Total para pop_total\n",
    "censo_temp03.rename(columns={'Total': 'pop_total', 'Unidade da Federação e Município':'unidade_no','Cód.':'unidade_co' }, inplace=True)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_temp03\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111940\n",
      "+----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------+\n",
      "|    | Ano   | Nível   |   unidade_co | unidade_no   | Sexo   | Cor ou raça   |   pop_total |   pop_under74 |\n",
      "|----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------|\n",
      "|  0 | _2010 | UF      |           11 | Rondônia     | Homens | Branca        |      274670 |        269314 |\n",
      "|  1 | _2010 | UF      |           11 | Rondônia     | Homens | Preta         |       60563 |         59252 |\n",
      "|  2 | _2010 | UF      |           11 | Rondônia     | Homens | Amarela       |       10126 |          9986 |\n",
      "|  3 | _2010 | UF      |           11 | Rondônia     | Homens | Parda         |      443524 |        437401 |\n",
      "|  4 | _2010 | UF      |           11 | Rondônia     | Homens | Indígena      |        6143 |          6037 |\n",
      "+----+-------+---------+--------------+--------------+--------+---------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# Gerar informação de UF a partir do split de 'Município', com o dividor '('\n",
    "censo_temp04 = censo_temp03.copy()\n",
    "\n",
    "censo_temp04['Ano'] = '_' + censo_temp04['Ano']\n",
    "\n",
    "# censo_pop_temp03['unidade_no'] = censo_pop_temp03['unidade_no'].str.split('(', expand=True)[0] # Permancer o código de UF depois do nome do município\n",
    "\n",
    "# # renomear coluna unidade_no para uf\n",
    "# censo_temp04.rename(columns={'unidade_no':'uf','Cód.':'uf_co'}, inplace=True)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_temp04\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro da tabela censo_uf_temp: 540\n",
      "Registro da tabela censo_mun_temp: 111400\n"
     ]
    }
   ],
   "source": [
    "# Dividir arquivos em UF e Municípios\n",
    "\n",
    "# Criar arquivo de UF\n",
    "censo_uf_temp = censo_temp04[censo_temp04['Nível'] == 'UF'].reset_index(drop=True)\n",
    "\n",
    "# Criar arquivo de Municípios\n",
    "censo_mun_temp = censo_temp04[censo_temp04['Nível'] == 'MU'].reset_index(drop=True)\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "print(f'Registro da tabela censo_uf_temp: {censo_uf_temp.shape[0]}')\n",
    "print(f'Registro da tabela censo_mun_temp: {censo_mun_temp.shape[0]}')\n",
    "# print(tabulate(censo_pop_uf_temp.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 540\n",
      "+----+-------+---------+----------+--------+---------------+-------------+---------------+\n",
      "|    | Ano   | uf_co   | uf_no    | Sexo   | Cor ou raça   |   pop_total |   pop_under74 |\n",
      "|----+-------+---------+----------+--------+---------------+-------------+---------------|\n",
      "|  0 | _2010 | _11     | Rondônia | Homens | Branca        |      274670 |        269314 |\n",
      "|  1 | _2010 | _11     | Rondônia | Homens | Preta         |       60563 |         59252 |\n",
      "|  2 | _2010 | _11     | Rondônia | Homens | Amarela       |       10126 |          9986 |\n",
      "|  3 | _2010 | _11     | Rondônia | Homens | Parda         |      443524 |        437401 |\n",
      "|  4 | _2010 | _11     | Rondônia | Homens | Indígena      |        6143 |          6037 |\n",
      "+----+-------+---------+----------+--------+---------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# Preparar para salvar arquivo de UF\n",
    "censo_uf_temp01 = censo_uf_temp.copy()\n",
    "\n",
    "# Excluir colunas desnecessárias\n",
    "censo_uf_temp01.drop(columns=['Nível'], inplace=True)\n",
    "\n",
    "# Renomear coluna unidade_no para uf_no\n",
    "censo_uf_temp01.rename(columns={'unidade_no': 'uf_no','unidade_co':'uf_co'}, inplace=True)\n",
    "\n",
    "censo_uf_temp01['uf_co'] = '_' + censo_uf_temp01['uf_co'].astype(str).str[:2]\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_uf_temp01\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111400\n",
      "+----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------+\n",
      "|    | Ano   | mun_co   | mun_no                     | Sexo   | Cor ou raça   |   pop_total |   pop_under74 | uf   |\n",
      "|----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------|\n",
      "|  0 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Branca        |        5311 |          5202 | RO   |\n",
      "|  1 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Preta         |         693 |           673 | RO   |\n",
      "|  2 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Amarela       |          96 |            94 | RO   |\n",
      "|  3 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Parda         |        6323 |          6206 | RO   |\n",
      "|  4 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Indígena      |         233 |           229 | RO   |\n",
      "+----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------+\n"
     ]
    }
   ],
   "source": [
    "# Preparar para salvar arquivo de Municipios\n",
    "censo_mun_temp01 = censo_mun_temp.copy()\n",
    "\n",
    "# Renomear coluna unidade_no para uf_no\n",
    "censo_mun_temp01.rename(columns={'unidade_no': 'mun_no','unidade_co': 'mun_co'}, inplace=True)\n",
    "\n",
    "# Mudar o formato de mun_cod para string e extrair os primeiros 7 dígitos\n",
    "# censo_mun_temp01['mun_co'] = censo_mun_temp01['mun_co'].astype(str).str[:6]\n",
    "\n",
    "# Acrescentar um '_' no início do valor da coluna mun_cod\n",
    "censo_mun_temp01['mun_co'] = '_' + censo_mun_temp01['mun_co'].astype(str).str[:6]\n",
    "\n",
    "# Criar campo uf com 2 caracteres entre parênteses do campo unidade_co\n",
    "censo_mun_temp01['uf'] = censo_mun_temp01['mun_no'].str[-3:-1]\n",
    "\n",
    "# Excluir colunas desnecessárias\n",
    "censo_mun_temp01.drop(columns=['Nível'], inplace=True)\n",
    "\n",
    "# Ordenar as colunas\n",
    "# censo_pop_mun_temp02 = censo_pop_mun_temp01[['Ano','uf_co','UF','mun_cod_sim','mun_no','pop_total','pop_under74']]\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_mun_temp01\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 2)\n",
      "   uf_co     uf_no\n",
      "0    _11  Rondônia\n",
      "10   _12      Acre\n",
      "20   _13  Amazonas\n",
      "30   _14   Roraima\n",
      "40   _15      Pará\n"
     ]
    }
   ],
   "source": [
    "# Fazer o merge com nome da UF\n",
    "censo_mun_temp01['uf_co'] = censo_mun_temp01.mun_co.str[:3]\n",
    "\n",
    "censo_uf_temp01_ = censo_uf_temp01[['uf_co','uf_no']]\n",
    "\n",
    "censo_uf_temp02_ = censo_uf_temp01_.drop_duplicates()\n",
    "\n",
    "print(censo_uf_temp02_.shape)\n",
    "print(censo_uf_temp02_.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros da tabela : 111400\n",
      "+----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------+---------+----------+\n",
      "|    | Ano   | mun_co   | mun_no                     | Sexo   | Cor ou raça   |   pop_total |   pop_under74 | uf   | uf_co   | uf_no    |\n",
      "|----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------+---------+----------|\n",
      "|  0 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Branca        |        5311 |          5202 | RO   | _11     | Rondônia |\n",
      "|  1 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Preta         |         693 |           673 | RO   | _11     | Rondônia |\n",
      "|  2 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Amarela       |          96 |            94 | RO   | _11     | Rondônia |\n",
      "|  3 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Parda         |        6323 |          6206 | RO   | _11     | Rondônia |\n",
      "|  4 | _2010 | _110001  | Alta Floresta D'Oeste (RO) | Homens | Indígena      |         233 |           229 | RO   | _11     | Rondônia |\n",
      "+----+-------+----------+----------------------------+--------+---------------+-------------+---------------+------+---------+----------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "censo_mun_temp02 = pd.merge(censo_mun_temp01,censo_uf_temp02_,on='uf_co',how='left')\n",
    "\n",
    "# mostrar dados gerais da tabela após transformações\n",
    "tab = censo_mun_temp02\n",
    "print(f'Registros da tabela : {tab.shape[0]}')\n",
    "print(tabulate(tab.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivo pronto - censo por municípios e por UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquivo de População Censo Tratado (pronto para merge)\n",
    "censo_uf_temp01.to_parquet('files_in_geral/censo_uf.parquet')\n",
    "\n",
    "# Salvar arquivo de População do Censo uf\n",
    "censo_mun_temp02.to_parquet('files_in_geral/censo_mun.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
